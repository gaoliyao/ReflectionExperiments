{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reflection Logistic Regression Experiment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaoliyao/ReflectionExperiments/blob/master/Reflection_Logistic_Regression_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qPQGOz2dPKFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "d07023ed-2993-4c41-dd67-6dbdddd4d3f4"
      },
      "cell_type": "code",
      "source": [
        "! [ ! -z \"$COLAB_GPU\" ] && pip install torch scikit-learn==0.20.* skorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 22kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x59450000 @  0x7fb9c55e12a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
            "\u001b[?25hCollecting scikit-learn==0.20.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/b2/05be9b6da9ae4a4c54f537be22e95833f722742a02b1e355fdc09363877c/scikit_learn-0.20.0-cp36-cp36m-manylinux1_x86_64.whl (5.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.3MB 4.1MB/s \n",
            "\u001b[?25hCollecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/9e/6a1f51fe538005d4fc2b28c270ffa0a2186ee4de345428811823bb4ba6eb/skorch-0.4.0-py3-none-any.whl (89kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.*) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.*) (1.14.6)\n",
            "Collecting tabulate (from skorch)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/c2/11d6845db5edf1295bc08b2f488cf5937806586afe42936c3f34c097ebdc/tabulate-0.8.2.tar.gz (45kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 17.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from skorch) (4.28.1)\n",
            "Building wheels for collected packages: tabulate\n",
            "  Running setup.py bdist_wheel for tabulate ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2a/85/33/2f6da85d5f10614cbe5a625eab3b3aebfdf43e7b857f25f829\n",
            "Successfully built tabulate\n",
            "Installing collected packages: torch, scikit-learn, tabulate, skorch\n",
            "  Found existing installation: scikit-learn 0.19.2\n",
            "    Uninstalling scikit-learn-0.19.2:\n",
            "      Successfully uninstalled scikit-learn-0.19.2\n",
            "Successfully installed scikit-learn-0.20.0 skorch-0.4.0 tabulate-0.8.2 torch-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OexME6nIQVmt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "57ce775a-03c9-427e-cb8a-d75ca603b565"
      },
      "cell_type": "code",
      "source": [
        "!pip install scipy"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oZ7SQU1tRvS4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.datasets import fetch_openml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "twHxAyXETU-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Reflection:\n",
        "    def __init__(self):\n",
        "        self.performance = 0\n",
        "        self.classifierDict = {} \n",
        "        self.trainData = []  # FloatTensor [{}, {}]\n",
        "        self.trainLabel = [] # LongTensor [{}, {}]\n",
        "        self.taskClassifier = None\n",
        "        self.errorTaskClassifier = [] #[{}, {}]\n",
        "        self.correctAndWrongSet = {} #[{}, {}]\n",
        "\n",
        "    def train(self, x, y):\n",
        "          print(\"Start training NN\")\n",
        "          print(len(x))\n",
        "          diff = self.trainSingleNeuralNetwork(len(self.classifierDict), x, y)\n",
        "          self.reflect(0, x, y, diff)\n",
        "          print(\"Ready to train taskClassifier\")\n",
        "          self.correctAndWrongSet[0] = self.trainData[0]\n",
        "          taskClassifier = TaskClassifierLayer(self.correctAndWrongSet)\n",
        "          self.taskClassifier = taskClassifier\n",
        "              \n",
        "    # Input: FloatTensor, LongTensor, list\n",
        "    # Return: FloatTensor, LongTensor\n",
        "    def getError(self, x, y, diff):\n",
        "          x = x.data.numpy()\n",
        "          y = y.data.numpy()\n",
        "          max = -1000\n",
        "          for i in diff:\n",
        "              if i > max:\n",
        "                  max = i\n",
        "          #print(max)\n",
        "\n",
        "          newX = []\n",
        "          newY = []\n",
        "          #print(diff)\n",
        "          for j in range(0, len(diff)):\n",
        "              if abs(diff[j]) > 0:\n",
        "                  #print(diff[j])\n",
        "                  k = x[j]\n",
        "                  newX.append(k.tolist())\n",
        "                  newY.append(y[j].tolist())\n",
        "          newX = torch.FloatTensor(newX)\n",
        "          newY = torch.LongTensor(newY)\n",
        "          return newX, newY\n",
        "    def reflect(self, id, x, y, diff):\n",
        "          newX, newY = self.getError(x, y, diff)\n",
        "          errorTaskClassifier = KMeans(n_clusters=8, init='k-means++', random_state=0)\n",
        "          \n",
        "          newY = newY.numpy()\n",
        "          newX = newX.numpy()\n",
        "          print(newY)\n",
        "          print(\"Ready to train taskClassifier\")\n",
        "          errorTaskClassifier.fit(newY)\n",
        "          self.errorTaskClassifier.append(errorTaskClassifier)\n",
        "          X0 = []\n",
        "          y0 = []\n",
        "          X1 = []\n",
        "          y1 = []\n",
        "          X2 = []\n",
        "          y2 = []\n",
        "          X3 = []\n",
        "          y3 = []\n",
        "          X4 = []\n",
        "          y4 = []\n",
        "          X5 = []\n",
        "          y5 = []\n",
        "          X6 = []\n",
        "          y6 = []\n",
        "          X7 = []\n",
        "          y7 = []\n",
        "          print(\"Ready to train operatorNetwork\")\n",
        "          for i in range(0, len(newY)):\n",
        "              data = newX[i]\n",
        "              target = newY[i]\n",
        "              clusterId = self.errorTaskClassifier[id].predict([target])\n",
        "              if i % 100 == 0:\n",
        "                  print(\"=======\")\n",
        "                  print(newY[i])\n",
        "                  print(clusterId)\n",
        "                  print(\"=======\")\n",
        "              data = data.tolist()\n",
        "              target = target.tolist()\n",
        "              if clusterId == 0:\n",
        "                  X0.append(data)\n",
        "                  y0.append(target)\n",
        "              elif clusterId == 1:\n",
        "                  X1.append(data)\n",
        "                  y1.append(target)\n",
        "              elif clusterId == 2:\n",
        "                  X2.append(data)\n",
        "                  y2.append(target)\n",
        "              elif clusterId == 3:\n",
        "                  X3.append(data)\n",
        "                  y3.append(target)\n",
        "              elif clusterId == 4:\n",
        "                  X4.append(data)\n",
        "                  y4.append(target)\n",
        "              elif clusterId == 5:\n",
        "                  X5.append(data)\n",
        "                  y5.append(target)\n",
        "              elif clusterId == 6:\n",
        "                  X6.append(data)\n",
        "                  y6.append(target)\n",
        "              elif clusterId == 7:\n",
        "                  X7.append(data)\n",
        "                  y7.append(target)\n",
        "\n",
        "          \n",
        "          self.correctAndWrongSet[1] = Variable(torch.FloatTensor(X0))\n",
        "          self.correctAndWrongSet[2] = Variable(torch.FloatTensor(X1))\n",
        "          self.correctAndWrongSet[3] = Variable(torch.FloatTensor(X2))\n",
        "          self.correctAndWrongSet[4] = Variable(torch.FloatTensor(X3))\n",
        "          self.correctAndWrongSet[5] = Variable(torch.FloatTensor(X4))\n",
        "          self.correctAndWrongSet[6] = Variable(torch.FloatTensor(X5))\n",
        "          self.correctAndWrongSet[7] = Variable(torch.FloatTensor(X6))\n",
        "          self.correctAndWrongSet[8] = Variable(torch.FloatTensor(X7))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X0)), Variable(torch.LongTensor(y0)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X1)), Variable(torch.LongTensor(y1)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X2)), Variable(torch.LongTensor(y2)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X3)), Variable(torch.LongTensor(y3)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X4)), Variable(torch.LongTensor(y4)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X5)), Variable(torch.LongTensor(y5)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X6)), Variable(torch.LongTensor(y6)))\n",
        "          self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X7)), Variable(torch.LongTensor(y7)))\n",
        "\n",
        "    def reflctWithoutKmeans(self, id, x, y, diff):\n",
        "        newX, newY = self.getError(x, y, diff)\n",
        "          \n",
        "        newY = newY.numpy()\n",
        "        newX = newX.numpy()\n",
        "        print(\"Ready to train taskClassifier\")\n",
        "        X0 = newX\n",
        "        y0 = newY\n",
        "          \n",
        "        self.correctAndWrongSet[id][1] = Variable(torch.FloatTensor(X0))\n",
        "        self.trainSingleNeuralNetwork(len(self.classifierDict), Variable(torch.FloatTensor(X0)), Variable(torch.LongTensor(y0)))\n",
        "          \n",
        "\n",
        "        \n",
        "    def convertNumpyToFloatList(self, x):\n",
        "        x = x.tolist()\n",
        "        x = torch.FloatTensor(x)\n",
        "        return x\n",
        "    # Input int, FloatTensor, LongTensor\n",
        "    # Output list\n",
        "    def trainSingleNeuralNetwork(self, num, X, y):\n",
        "        print(\"Train Single NN\")\n",
        "        print(\"number\", num)\n",
        "        print(\"x\", len(X))\n",
        "        #s = x.data.numpy().shape\n",
        "        print(type(X))\n",
        "        print(type(y))\n",
        "        clf = None\n",
        "        diff = []\n",
        "        print(__doc__)\n",
        "\n",
        "        # Author: Arthur Mensch <arthur.mensch@m4x.org>\n",
        "        # License: BSD 3 clause\n",
        "\n",
        "        # Turn down for faster convergence\n",
        "        t0 = time.time()\n",
        "        train_samples = len(X)\n",
        "\n",
        "        # Load data from https://www.openml.org/d/554\n",
        "        #X, y = fetch_openml('mnist_784', cache = False, version=1, return_X_y=True)\n",
        "\n",
        "        random_state = check_random_state(0)\n",
        "        permutation = random_state.permutation(X.shape[0])\n",
        "        X = X[permutation]\n",
        "        y = y[permutation]\n",
        "        X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "        #X_train, X_test, y_train, y_test = train_test_split(\n",
        "        #    X, y, train_size=train_samples, test_size=10000)\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X = scaler.fit_transform(X)\n",
        "        #X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Turn up tolerance for faster convergence\n",
        "        clf = LogisticRegression(C=50. / train_samples,\n",
        "                                 multi_class='multinomial',\n",
        "                                 penalty='l1', solver='saga', tol=0.1)\n",
        "        clf.fit(X, y)\n",
        "        sparsity = np.mean(clf.coef_ == 0) * 100\n",
        "        score = clf.score(X, y)\n",
        "        #print('Best C % .4f' % clf.C_)\n",
        "        print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
        "        print(\"Test score with L1 penalty: %.4f\" % score)\n",
        "\n",
        "        coef = clf.coef_.copy()\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        scale = np.abs(coef).max()\n",
        "        for i in range(10):\n",
        "            l1_plot = plt.subplot(2, 5, i + 1)\n",
        "            l1_plot.imshow(coef[i].reshape(28, 28), interpolation='nearest',\n",
        "                           cmap=plt.cm.RdBu, vmin=-scale, vmax=scale)\n",
        "            l1_plot.set_xticks(())\n",
        "            l1_plot.set_yticks(())\n",
        "            l1_plot.set_xlabel('Class %i' % i)\n",
        "        plt.suptitle('Classification vector for...')\n",
        "\n",
        "        run_time = time.time() - t0\n",
        "        print('Example run in %.3f s' % run_time)\n",
        "        plt.show()\n",
        "        for i in range(0, len(X)):\n",
        "            prediction = clf.predict(X[i])\n",
        "            diff.append(prediction.numpy()[0] - y.numpy()[i][0])\n",
        "\n",
        "        print('Finished Training')\n",
        "            \n",
        "        \n",
        "        self.classifierDict[num] = clf\n",
        "        self.trainData.append(x)\n",
        "        self.trainLabel.append(y)\n",
        "        \n",
        "        #print(len(x))\n",
        "        \n",
        "        #print(diff)\n",
        "        return diff\n",
        "\n",
        "    def test(self):\n",
        "        return 0.5\n",
        "\n",
        "    def getDifference(self, x, diff):\n",
        "        pass\n",
        "\n",
        "    def predict(self, data):\n",
        "        prediction = []\n",
        "        #for data in X:\n",
        "        data = data.data.numpy().tolist()\n",
        "        data = Variable(torch.FloatTensor(data))\n",
        "        \n",
        "        #print(len(self.taskClassifier))\n",
        "        #taskId = self.sensoryCortex.predictSensoryID(data.data.numpy().tolist())\n",
        "        #print(taskId)\n",
        "        predictClusterId = self.taskClassifier.predictCluster(data)\n",
        "        net= self.classifierDict[predictClusterId[0]]\n",
        "        for nId in self.classifierDict.keys():\n",
        "            n = self.classifierDict[nId]\n",
        "            output = n(data)\n",
        "            shapeData = data.data.numpy().shape\n",
        "            if shapeData[3] == 28:                \n",
        "                _, prediction = torch.max(output.data, 1)\n",
        "            else:\n",
        "                _, prediction = torch.max(output.data, 1)\n",
        "        predictOutput = net(data)\n",
        "        \n",
        "        return predictOutput"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_UdKr0GTWJF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from torch.autograd import Variable\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from torch.autograd import Variable\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class TaskClassifierLayer:\n",
        "    def __init__(self, correctAndWrongCluster):\n",
        "        self.correctAndWrongVariables = correctAndWrongCluster\n",
        "        self.correctAndWrong = {}\n",
        "#         self.clf3 = LogisticRegression(C=50. / 70000, multi_class='multinomial', penalty='l1', solver='saga', tol=0.1)\n",
        "        self.clf = tree.DecisionTreeClassifier()\n",
        "#        self.clf2 = GaussianNB()\n",
        "#         self.clf4 = KNeighborsClassifier(3)\n",
        "#         self.clf5 = MLPClassifier(alpha=1)\n",
        "#         self.clf6 =  AdaBoostClassifier()\n",
        "#         self.clf7 = SVC(gamma=2, C=1)\n",
        "#         self.clf8 = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
        "        self.getCorrectAndWrongCluster()\n",
        "        self.trainClassifier()\n",
        "    def getCorrectAndWrongCluster(self):\n",
        "        #print(self.correctAndWrong)\n",
        "        # list output in this for loop\n",
        "        for i in self.correctAndWrongVariables.keys():\n",
        "            j = self.correctAndWrongVariables[i]\n",
        "            j = j.data.numpy()\n",
        "            for num in j:\n",
        "                if i not in self.correctAndWrong.keys():\n",
        "                    self.correctAndWrong[i] = [num[0]]\n",
        "                else:\n",
        "                    self.correctAndWrong[i].append(num[0])\n",
        "        for i in self.correctAndWrong.keys():\n",
        "            if i != 0:\n",
        "                for j in self.correctAndWrong[i]:\n",
        "                    #newCluster = self.clusters[0]\n",
        "                    for k in range(0, len(self.correctAndWrong[0])):\n",
        "                        if np.array_equal(np.array(self.correctAndWrong[0][k]), np.array(j)):\n",
        "                            self.correctAndWrong[0].pop(k)\n",
        "                            break\n",
        "        print(\"data ready\")\n",
        "        \n",
        "                            \n",
        "        #print(self.clusters[0])\n",
        "        \n",
        "    def trainClassifier(self):\n",
        "        X = []\n",
        "        y = []\n",
        "        for i in self.correctAndWrong.keys():\n",
        "            print(i)\n",
        "            cluster = self.correctAndWrong[i]\n",
        "            #print(cluster)\n",
        "            for j in cluster:\n",
        "                X.append([j])\n",
        "                y.append(i)\n",
        "        #print(X)\n",
        "        #print(y)\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        #print(X.shape)\n",
        "        #print(y.shape)\n",
        "        num, color, pic, pixX, pixY = X.shape\n",
        "        X = X.reshape(num, pixX*pixY*color*pic)\n",
        "        num = y.shape\n",
        "        y = y.reshape(num)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)\n",
        "#         self.clf = self.clf.fit(X_train, y_train)\n",
        "#         prediction = self.clf.predict(X_test)\n",
        "#         print(\"performanceNeuralNetwork DT\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction))\n",
        "        \n",
        "#         self.clf2 = self.clf2.fit(X_train, y_train)\n",
        "#         prediction2 = self.clf2.predict(X_test)\n",
        "#         print(\"performanceNeuralNetwork GaussianNB\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction2))\n",
        "        \n",
        "#         self.clf3 = self.clf3.fit(X_train, y_train)\n",
        "#         prediction3 = self.clf3.predict(X_test)\n",
        "#         print(\"performanceNeuralNetwork LogReg\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction3))\n",
        "        \n",
        "        self.clf = self.clf.fit(X_train, y_train)\n",
        "#         prediction2 = self.clf.predict(X_test)\n",
        "#         print(\"performanceNeuralNetwork KNeighborsClassifier\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction2))\n",
        "        \n",
        "#         self.clf5 = self.clf5.fit(X_train, y_train)\n",
        "#         prediction = self.clf5.predict(X_test)\n",
        "#         print(\"performanceNeuralNetwork MLPClassifier\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction))\n",
        "        \n",
        "#         self.clf6 = self.clf6.fit(X_train, y_train)\n",
        "#         prediction6 = self.clf6.predict(X_test)\n",
        "#         print(\"performanceNeuralNetwork AdaBoostClassifier\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction6))\n",
        "        \n",
        "#         self.clf7 = self.clf7.fit(X_train, y_train)       \n",
        "#         prediction7 = self.clf7.predict(X_test)    \n",
        "#         print(\"performanceNeuralNetwork SVC\")\n",
        "#         print(self.my_custom_loss_func(y_test, prediction7))\n",
        "#sffs\n",
        "        \n",
        "\n",
        "    def getClusters(self):\n",
        "        # list output in this for loop\n",
        "        for i in self.clustersVariables.keys():\n",
        "            j = self.clustersVariables[i]\n",
        "            j = j.data.numpy()\n",
        "            for num in j:\n",
        "                if i not in self.clusters.keys():\n",
        "                    self.clusters[i] = [num[0]]\n",
        "                else:\n",
        "                    self.clusters[i].append(num[0])\n",
        "        for i in self.clusters.keys():\n",
        "            if i != 0:\n",
        "                for j in self.clusters[i]:\n",
        "                    #newCluster = self.clusters[0]\n",
        "                    for k in range(0, len(self.clusters[0])):\n",
        "                        if np.array_equal(np.array(self.clusters[0][k]), np.array(j)):\n",
        "                            self.clusters[0].pop(k)\n",
        "                            break\n",
        "                            \n",
        "        #print(self.clusters[0])\n",
        "    # Variable\n",
        "    def predictCluster(self, x):\n",
        "        #print(self.clusterRanges)\n",
        "        num, color, pixX, pixY = x.shape\n",
        "        x = x.data.numpy()\n",
        "        x = x.reshape(num, pixX*pixY*color)\n",
        "        clusterId = self.clf.predict(x)\n",
        "        return clusterId\n",
        "    def dist(self, a, b):\n",
        "        return abs(a-b)\n",
        "    def my_custom_loss_func(self, ground_truth, predictions):\n",
        "        diff = np.abs(ground_truth - predictions)\n",
        "        num = 0.0\n",
        "        count = 0.0\n",
        "        for i in diff:\n",
        "            count += 1\n",
        "            if i == 0:\n",
        "                num += 1\n",
        "        return float(num)/float(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ep7jozd5VKDR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46113489-53c1-4614-99e7-59b23d036919"
      },
      "cell_type": "code",
      "source": [
        "X, y = fetch_openml('mnist_784', cache = False, version=1, return_X_y=True)\n",
        "print(len(X))\n",
        "random_state = check_random_state(0)\n",
        "permutation = random_state.permutation(X.shape[0])\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=60000, test_size=10000)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5fyOARcKU8Fd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4722
        },
        "outputId": "1136f40a-4d9e-48a7-a7ac-c034681ec60b"
      },
      "cell_type": "code",
      "source": [
        "c = Reflection()\n",
        "print(len(X_train))\n",
        "c.train(X_train, y_train)\n",
        "#c.train(EMNIST_trainloader, EMNIST_testloader)\n",
        "\n",
        "\n",
        "# for i in c.taskClassifier.clusters.keys():\n",
        "X_test = scaler.transform(X_test)\n",
        "score = clf.score(X_test, y_test)\n",
        "print(\"Test score with L1 penalty: %.4f\" % score)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "Start training NN\n",
            "60000\n",
            "Train Single NN\n",
            "number 0\n",
            "x 60000\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "Automatically created module for IPython interactive environment\n",
            "Sparsity with L1 penalty: 83.12%\n",
            "Test score with L1 penalty: 0.8400\n",
            "Example run in 27.470 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAFCCAYAAAD1zwe2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY8BDRERE2mPAQ0RERNr7fxgk7/ebjy1gAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7aecc6fe10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-99824ec9d907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReflection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#c.train(EMNIST_trainloader, EMNIST_testloader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-37a9a0bd3386>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start training NN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m           \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainSingleNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifierDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ready to train taskClassifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-37a9a0bd3386>\u001b[0m in \u001b[0;36mtrainSingleNeuralNetwork\u001b[0;34m(self, num, X, y)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    255\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n -4.41807799e-03 -5.75481961e-03 -4.08251693e-03 -4.08251693e-03\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n -4.08251693e-03 -6.22758214e-03 -8.37776379e-03 -1.12586613e-02\n -1.52510392e-02 -1.97365628e-02 -2.36109724e-02 -2.91862407e-02\n -3.20045016e-02 -3.26034189e-02 -3.38242492e-02 -3.11962830e-02\n -3.01780433e-02 -2.77001140e-02 -2.34578282e-02 -1.90210813e-02\n -1.70023177e-02 -9.69504016e-03 -5.63566723e-03 -4.08251693e-03\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00 -4.08251693e-03 -4.08251693e-03\n -8.52241235e-03 -1.09191410e-02 -1.83876746e-02 -2.82060309e-02\n -3.73843814e-02 -5.24748869e-02 -6.87613818e-02 -8.75978659e-02\n -1.03542793e-01 -1.18407771e-01 -1.30306218e-01 -1.38839797e-01\n -1.38876786e-01 -1.31032488e-01 -1.18765837e-01 -1.00681169e-01\n -7.87649700e-02 -5.69094098e-02 -3.88606168e-02 -2.36923808e-02\n -1.26577293e-02 -7.14917835e-03  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00 -5.36837753e-03 -8.09533241e-03\n -1.29736069e-02 -2.18512709e-02 -3.53527022e-02 -5.49640930e-02\n -7.91591553e-02 -1.08182915e-01 -1.38620779e-01 -1.70378983e-01\n -2.00619385e-01 -2.27370070e-01 -2.48800835e-01 -2.61133654e-01\n -2.60758394e-01 -2.45520687e-01 -2.20262285e-01 -1.85634248e-01\n -1.46929538e-01 -1.07315183e-01 -7.68789726e-02 -4.79556077e-02\n -2.99323433e-02 -1.60407629e-02 -6.48517340e-03  0.00000000e+00\n  0.00000000e+00 -4.08251693e-03 -7.76342302e-03 -1.40969029e-02\n -2.32858721e-02 -4.81743370e-02 -7.90867731e-02 -1.16827257e-01\n -1.62128688e-01 -2.14596718e-01  3.06961941e-01  1.15529739e+00\n  1.70886850e+00  1.42315923e+00  1.24722777e+00  1.16835614e+00\n  1.19620934e+00  1.89839405e+00  1.23788095e+00 -2.29919436e-01\n -2.83214839e-01 -2.15764529e-01 -1.57484698e-01 -1.08431973e-01\n -7.03224474e-02 -3.82797104e-02 -1.45358787e-02 -4.08251693e-03\n  0.00000000e+00 -4.08251693e-03 -1.21480802e-02 -2.21488897e-02\n -5.12012464e-02 -9.01258878e-02 -1.39909315e-01  4.28270314e-01\n  1.33555646e+00  2.61675472e+00  2.73951212e+00  2.42677250e+00\n  2.02905050e+00  1.74210438e+00  1.56941137e+00  1.49918259e+00\n  1.52300006e+00  1.65279477e+00  1.90401018e+00  1.19021055e+00\n -4.07537340e-01 -3.45864657e-01 -2.59535899e-01 -1.88481758e-01\n -1.29825672e-01 -7.35283122e-02 -3.16968568e-02 -7.32230759e-03\n  0.00000000e+00 -5.57015293e-03 -1.53585154e-02 -3.55873273e-02\n -7.81153073e-02 -1.31721577e-01  3.25962948e+00  4.23043416e+00\n  3.46501262e+00  2.62390380e+00  2.11400036e+00  1.69709026e+00\n  4.65378957e-01 -2.42895495e-02 -7.74219661e-01 -8.23534148e-01\n -8.00480917e-01 -6.33683119e-01  1.09137246e+00  1.72682562e+00\n  5.54354323e-02 -4.49566533e-01 -3.37109240e-01 -2.46399141e-01\n -1.71895252e-01 -1.02975935e-01 -4.77484245e-02 -1.49954008e-02\n -4.08251693e-03 -1.32211364e-02 -2.68854762e-02 -6.02526190e-02\n -1.13785950e-01 -1.77137873e-01  2.82265730e+00  3.63669971e+00\n  1.05723912e+00 -5.86195878e-01 -7.28640558e-01 -8.80845876e-01\n -1.01779431e+00 -1.13405720e+00 -1.20322349e+00 -1.22892375e+00\n -1.20804509e+00 -1.11020637e+00  6.24612628e-01  1.47673229e+00\n  4.92056778e-01 -5.28969554e-01 -3.94113222e-01 -2.84665385e-01\n -1.95475242e-01 -1.20706219e-01 -5.65236597e-02 -1.60625208e-02\n -5.02549298e-03 -1.80438983e-02 -4.39654559e-02 -8.49289715e-02\n -1.39269335e-01 -2.09200613e-01  2.34803573e+00  3.10332017e+00\n -1.71924091e-01 -6.85403159e-01 -8.49977442e-01 -9.86898516e-01\n -1.07593014e+00 -1.10562693e+00 -1.10334680e+00 -1.10124873e+00\n -1.10690472e+00 -9.04153828e-01  1.23416609e+00  1.39291936e+00\n -3.70692798e-01 -5.65665520e-01 -4.18882164e-01 -2.95504602e-01\n -1.97549169e-01 -1.20778898e-01 -5.62489848e-02 -1.49826201e-02\n -6.22076047e-03 -2.21109400e-02 -5.30898765e-02 -9.31502412e-02\n -1.50016701e-01 -2.24438307e-01 -5.54022305e-02  4.95374841e-01\n -5.44405518e-01 -7.55705019e-01 -9.08813055e-01 -9.95533029e-01\n -9.93448445e-01 -9.44990377e-01 -9.05434187e-01 -9.11652220e-01\n -9.54682272e-01 -7.62058845e-01  1.27980957e+00  1.37279018e+00\n -6.37085899e-01 -5.63348593e-01 -4.16738671e-01 -2.87765957e-01\n -1.81970194e-01 -1.05935942e-01 -4.90965059e-02 -1.60567320e-02\n -5.74508293e-03 -2.22714505e-02 -5.26984963e-02 -9.19397878e-02\n -1.46506020e-01 -2.25287467e-01 -3.30868837e-01 -4.62378017e-01\n -6.22686973e-01 -7.91972074e-01 -9.15148247e-01 -9.33401550e-01\n -8.64339484e-01 -7.92832196e-01 -7.69837884e-01 -8.03453821e-01\n -8.75523951e-01  4.18227566e-01  1.33135583e+00  3.72730136e-01\n -6.99336571e-01 -5.33790303e-01 -3.94312874e-01 -2.69629338e-01\n -1.60959280e-01 -8.21690449e-02 -3.85247930e-02 -1.30704935e-02\n -6.04096266e-03 -2.03382301e-02 -4.68556472e-02 -8.14272971e-02\n -1.35668131e-01 -2.23551858e-01 -3.36523428e-01 -4.83252232e-01\n -6.53102408e-01 -8.15824459e-01 -9.01784349e-01 -8.71490254e-01\n -7.80528522e-01 -7.30601630e-01 -7.40067289e-01 -8.02512520e-01\n -2.36503920e-01  1.29965788e+00  1.15843999e+00 -5.30219144e-01\n -6.54946392e-01 -4.97096178e-01 -3.68283877e-01 -2.56538748e-01\n -1.50648660e-01 -6.21784194e-02 -2.85708325e-02 -7.63757934e-03\n -5.30435130e-03 -1.62980974e-02 -3.58019460e-02 -6.82226923e-02\n -1.26066741e-01 -2.24980604e-01 -3.51197001e-01 -5.09309303e-01\n -6.83798351e-01 -8.32831237e-01 -8.91543569e-01 -8.41083478e-01\n -7.64716200e-01 -7.68499274e-01 -8.20380240e-01 -8.82514485e-01\n  7.52273827e-01  1.21362215e+00  2.44025084e-01 -7.95332689e-01\n -6.15897221e-01 -4.67830608e-01 -3.53738646e-01 -2.54197232e-01\n -1.54315823e-01 -5.37417744e-02 -2.18632928e-02 -8.89093771e-03\n  0.00000000e+00 -1.09502561e-02 -2.48524201e-02 -5.64579096e-02\n -1.22788368e-01 -2.37493823e-01 -3.72507999e-01 -5.33965544e-01\n -7.03630266e-01 -8.38771893e-01 -8.79367054e-01 -8.38604486e-01\n -8.13869120e-01 -8.90140026e-01 -9.80256082e-01  6.47186584e-03\n  1.12585854e+00  7.29853664e-01 -9.78343369e-01 -7.76087483e-01\n -5.94423673e-01 -4.59730127e-01 -3.54171086e-01 -2.62591090e-01\n -1.64441673e-01 -5.88413596e-02 -2.20646192e-02 -5.76048346e-03\n  0.00000000e+00 -7.63015654e-03 -1.80964555e-02 -5.04891463e-02\n -1.27379030e-01 -2.55751083e-01 -3.93697082e-01 -5.50122713e-01\n -7.07665437e-01 -8.25974633e-01 -8.65493318e-01 -8.58034164e-01\n -9.01195061e-01 -1.03362963e+00 -6.80911213e-01  8.67875450e-01\n  7.58972792e-01 -8.49465329e-01 -9.65008600e-01 -7.62102625e-01\n -5.95638480e-01 -4.71206018e-01 -3.67081475e-01 -2.72974822e-01\n -1.73615802e-01 -6.96030910e-02 -2.33675823e-02 -6.83243031e-03\n -4.08251693e-03 -4.18942802e-03 -1.91300864e-02 -5.22040497e-02\n -1.38468408e-01 -2.74718632e-01 -4.09313326e-01 -5.52573784e-01\n -6.90520440e-01 -7.90833966e-01 -8.39427388e-01 -8.68825147e-01\n -9.59453728e-01 -1.09620150e+00  8.07775967e-01  1.04586646e+00\n  1.84321378e-01 -1.08050717e+00 -9.23562974e-01 -7.51482191e-01\n -6.08629542e-01 -4.85959449e-01 -3.79965732e-01 -2.78205935e-01\n -1.75553136e-01 -7.68084730e-02 -2.80583864e-02 -7.39068300e-03\n -4.08251693e-03 -7.63984804e-03 -2.24130236e-02 -6.03192250e-02\n -1.54961182e-01 -2.94404716e-01 -4.18763428e-01 -5.43104389e-01\n -6.57486746e-01 -7.40386051e-01 -7.87543664e-01 -8.33362906e-01\n -8.11541880e-01  2.37545657e-01  1.07650250e+00  5.85459942e-01\n -9.14782140e-01 -1.00375931e+00 -8.80062037e-01 -7.43715278e-01\n -6.16304347e-01 -4.92956978e-01 -3.78990574e-01 -2.72567792e-01\n -1.72648347e-01 -8.29019723e-02 -3.24869949e-02 -8.64814370e-03\n  0.00000000e+00 -8.00351192e-03 -2.57349684e-02 -7.35047735e-02\n -1.76203435e-01 -3.10842455e-01 -4.25734449e-01 -5.32641526e-01\n -6.20306376e-01 -6.84108156e-01 -7.25583070e-01 -7.66928875e-01\n  1.21044806e-02  1.36913240e+00  1.20993273e+00 -5.26683547e-01\n -1.01462096e+00 -9.57748855e-01 -8.58750602e-01 -7.42734821e-01\n -6.15225432e-01 -4.85193841e-01 -3.67052257e-01 -2.59910902e-01\n -1.66676155e-01 -8.73776542e-02 -3.38663663e-02 -1.09269978e-02\n -5.90596678e-03 -7.26442897e-03 -3.32762751e-02 -9.11218876e-02\n -1.96993588e-01 -3.25311625e-01 -4.36311592e-01 -5.33199546e-01\n -6.06774951e-01 -6.61090338e-01 -6.99942847e-01  4.79118373e-01\n  1.57537235e+00  1.37361913e+00 -7.16466503e-01 -1.01342137e+00\n -1.01572167e+00 -9.59228916e-01 -8.63807492e-01 -7.36680424e-01\n -5.96763064e-01 -4.63106487e-01 -3.46733466e-01 -2.44011257e-01\n -1.55833592e-01 -8.39687820e-02 -3.05751997e-02 -9.78345648e-03\n -4.08251693e-03 -1.09558884e-02 -3.88323714e-02 -1.03280232e-01\n -2.09383904e-01 -3.35053737e-01 -4.49283710e-01 -5.51039733e-01\n -6.33115526e-01 -6.95278659e-01  5.35373959e-02  1.52025531e+00\n  1.40004157e+00 -2.00837277e-01 -1.00932764e+00 -1.06353100e+00\n -1.05576255e+00 -9.72410401e-01 -8.52669769e-01 -7.04423997e-01\n -5.56977558e-01 -4.26419824e-01 -3.14744583e-01 -2.18192521e-01\n -1.39246062e-01 -7.61840747e-02 -2.82279784e-02 -7.37530135e-03\n  0.00000000e+00 -1.05564152e-02 -4.26699001e-02 -1.08726750e-01\n -2.06211247e-01 -3.27958491e-01 -4.51822408e-01 -5.67799378e-01\n -6.42818376e-01  8.11927646e-01  1.40137228e+00  1.37373782e+00\n -2.76964094e-01 -1.05235873e+00 -1.12418621e+00 -1.13405424e+00\n -1.07066839e+00 -9.44680814e-01 -7.92704424e-01 -6.29014274e-01\n -4.88562618e-01 -3.67781506e-01 -2.67447229e-01 -1.84257445e-01\n -1.20036861e-01 -6.56193017e-02 -2.54713009e-02 -5.77331594e-03\n -4.08251693e-03 -9.43222662e-03 -4.10161933e-02 -9.93445111e-02\n -1.86503356e-01 -2.97612179e-01 -4.24107259e-01 -4.45223903e-01\n  5.80269783e-01  1.53273706e+00  1.37450174e+00  3.53318723e-01\n -8.06611221e-01 -8.85371019e-01 -9.00488029e-01 -8.35050493e-01\n -7.02297620e-01 -5.30413193e-01 -3.39049571e-01 -1.43821974e-01\n  6.57997595e-02  3.12574011e-01  6.26862109e-01  1.05843881e+00\n  4.76993203e-01 -4.96485750e-02 -1.88047573e-02 -4.08251693e-03\n -4.08251693e-03 -6.00490574e-03 -3.27500335e-02 -7.82348723e-02\n -1.46370407e-01 -2.41292859e-01 -3.57684089e-01  4.39671329e-01\n  1.97723924e+00  1.61657665e+00  1.38839958e+00  1.24836478e+00\n  1.16881424e+00  1.14381725e+00  1.18067852e+00  1.31231147e+00\n  1.54335030e+00  1.89096213e+00  2.41158043e+00  3.16632078e+00\n  4.29683605e+00  6.00085868e+00  8.59972760e+00  1.25974405e+01\n  1.68811941e+01  2.01899957e+01 -1.25221734e-02 -4.08251693e-03\n  0.00000000e+00 -4.08251693e-03 -2.20143532e-02 -5.17520455e-02\n -9.95340309e-02 -1.66612417e-01 -2.58169902e-01 -1.82660367e-01\n  5.60209255e-01  1.10504265e+00  1.69478150e+00  6.32933686e-01\n  1.39231903e+00  1.39964927e+00  5.81000928e-01  6.78843178e-01\n  9.35903379e-01  1.29269936e+00  1.79838128e+00  2.49424881e+00\n  3.47201178e+00  4.98022637e+00  7.28952459e+00  1.00089268e+01\n  1.64651681e+01  2.68348483e+01 -9.70518130e-03  0.00000000e+00\n  0.00000000e+00  0.00000000e+00 -9.75112166e-03 -2.75349201e-02\n -5.58560853e-02 -9.36651504e-02 -1.51729744e-01 -2.21734233e-01\n -3.02082878e-01 -3.86078743e-01 -4.67831593e-01 -5.31522021e-01\n -5.66869495e-01 -5.65521669e-01 -5.30663557e-01 -4.71805773e-01\n -3.98794151e-01 -3.25955048e-01 -2.54832887e-01 -1.92742154e-01\n -1.43807294e-01 -9.99824069e-02 -6.93277411e-02 -4.65631666e-02\n -2.51985069e-02 -1.10841656e-02 -4.75287492e-03  0.00000000e+00\n  0.00000000e+00  0.00000000e+00 -6.66430111e-03 -9.46529869e-03\n -2.62896373e-02 -5.02760113e-02 -8.54122941e-02 -1.27487484e-01\n -1.75408842e-01 -2.22736285e-01 -2.65112791e-01 -2.94810735e-01\n -3.09095202e-01 -3.07918937e-01 -2.92619637e-01 -2.67033905e-01\n -2.36109113e-01 -2.01041028e-01 -1.62581673e-01 -1.26135934e-01\n -9.28371322e-02 -6.42501065e-02 -4.47598460e-02 -2.87048593e-02\n -1.64604284e-02 -6.84103301e-03 -4.08251693e-03  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.08251693e-03\n -1.48115490e-02 -3.05404933e-02 -5.24190947e-02 -7.83849705e-02\n -1.08280736e-01 -1.33453981e-01 -1.56156829e-01 -1.74817912e-01\n -1.83489535e-01 -1.81759488e-01 -1.71607036e-01 -1.53859643e-01\n -1.35512991e-01 -1.16218183e-01 -9.29276119e-02 -7.20950034e-02\n -5.27167243e-02 -3.64687966e-02 -2.20782759e-02 -1.27554495e-02\n -6.56230222e-03 -4.08251693e-03  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n -5.79016363e-03 -7.56320813e-03 -1.40728825e-02 -2.12891047e-02\n -2.69807356e-02 -3.20663634e-02 -4.20354532e-02 -4.56802440e-02\n -5.19393791e-02 -5.61857346e-02 -5.92379380e-02 -5.45275292e-02\n -4.97596305e-02 -4.23612080e-02 -3.25590781e-02 -2.24191811e-02\n -1.62208284e-02 -1.09299175e-02 -7.59519218e-03 -5.77039393e-03\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "aP8pb3-8O9wZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1796
        },
        "outputId": "d5dad700-ce64-492a-b31e-a57d6af74f4e"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "print(__doc__)\n",
        "\n",
        "# Author: Arthur Mensch <arthur.mensch@m4x.org>\n",
        "# License: BSD 3 clause\n",
        "\n",
        "# Turn down for faster convergence\n",
        "t0 = time.time()\n",
        "train_samples = 5000\n",
        "\n",
        "# Load data from https://www.openml.org/d/554\n",
        "X, y = fetch_openml('mnist_784', cache = False, version=1, return_X_y=True)\n",
        "\n",
        "random_state = check_random_state(0)\n",
        "permutation = random_state.permutation(X.shape[0])\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, train_size=train_samples, test_size=10000)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Turn up tolerance for faster convergence\n",
        "clf = LogisticRegression(C=50. / train_samples,\n",
        "                         multi_class='multinomial',\n",
        "                         penalty='l1', solver='saga', tol=0.1)\n",
        "clf.fit(X_train, y_train)\n",
        "sparsity = np.mean(clf.coef_ == 0) * 100\n",
        "score = clf.score(X_test, y_test)\n",
        "# print('Best C % .4f' % clf.C_)\n",
        "print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
        "print(\"Test score with L1 penalty: %.4f\" % score)\n",
        "\n",
        "coef = clf.coef_.copy()\n",
        "plt.figure(figsize=(10, 5))\n",
        "scale = np.abs(coef).max()\n",
        "for i in range(10):\n",
        "    l1_plot = plt.subplot(2, 5, i + 1)\n",
        "    l1_plot.imshow(coef[i].reshape(28, 28), interpolation='nearest',\n",
        "                   cmap=plt.cm.RdBu, vmin=-scale, vmax=scale)\n",
        "    l1_plot.set_xticks(())\n",
        "    l1_plot.set_yticks(())\n",
        "    l1_plot.set_xlabel('Class %i' % i)\n",
        "plt.suptitle('Classification vector for...')\n",
        "\n",
        "run_time = time.time() - t0\n",
        "print('Example run in %.3f s' % run_time)\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-677bd1048601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Load data from https://www.openml.org/d/554\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_784'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_X_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/datasets/openml.py\u001b[0m in \u001b[0;36mfetch_openml\u001b[0;34m(name, version, data_id, data_home, target_column, cache, return_X_y)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;31m# obtain the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     arff = _download_data_arff(data_description['file_id'], return_sparse,\n\u001b[0;32m--> 544\u001b[0;31m                                data_home)\n\u001b[0m\u001b[1;32m    545\u001b[0m     \u001b[0marff_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     nominal_attributes = {k: v for k, v in arff['attributes']\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/datasets/openml.py\u001b[0m in \u001b[0;36m_download_data_arff\u001b[0;34m(file_id, sparse, data_home, encode_nominal)\u001b[0m\n\u001b[1;32m    323\u001b[0m                                return_type=return_type, )\n\u001b[1;32m    324\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         arff_file = _arff.loads(response.read().decode('utf-8'),\n\u001b[0m\u001b[1;32m    326\u001b[0m                                 \u001b[0mencode_nominal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_nominal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                                 return_type=return_type)\n",
            "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;31m# Read a chunk of data from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mchunk_left\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_readinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_bytes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_safe_readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_mvb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                 \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal_bytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1009\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}